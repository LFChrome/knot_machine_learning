{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac03926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import time, random\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5e5add",
   "metadata": {},
   "source": [
    "# <center>Cost Function and Gradient as Matrix Multiplication</center>\n",
    "\n",
    "We defined our function as $J(\\theta)=\\frac{1}{m}\\sum_{i=1}^{m}-y_i\\log{(g(x_{i,*}\\theta))}-(1-y_i)\\log{(1-g(x_{i,*}\\theta))}$, where $g(z)=\\frac{1}{1+e^{-z}}$. Rewriting the inside summation\n",
    "\n",
    "$$\n",
    "-y_i\\log{(g(x_{i,*}\\theta))}-(1-y_i)\\log{(1-g(x_{i,*}\\theta))}=\n",
    "y_i\\log{(1+e^{-x_{i,*}\\theta})}-(1-y_i)\\log{(e^{-x_{i,*}\\theta})}+(1-y_i)\\log{(1+e^{-x_{i,*}\\theta})}\n",
    "$$\n",
    "\n",
    "$$\n",
    "=(1-y_i)(x_{i,*}\\theta)+\\log{(1+e^{-x_{i,*}\\theta})}\n",
    "$$\n",
    "\n",
    "$$\n",
    "=\\log{(1+e^{-x_{i,*}\\theta})}+(x_{i,*}\\theta)-(y_i)(x_{i,*}\\theta)\n",
    "$$\n",
    "\n",
    "$$\n",
    "=\\log{(1+e^{-x_{i,*}\\theta})}-\\ln{(e^{-x_{i,*}\\theta})}-(y_i)(x_{i,*}\\theta)\n",
    "$$\n",
    "\n",
    "$$\n",
    "=\\log{(1+e^{x_{i,*}\\theta})}-(y_i)(x_{i,*}\\theta)\n",
    "$$\n",
    "\n",
    "Hence, a more compact way of expressing the cost function is: \n",
    "\n",
    "$$J(\\theta)=\\frac{1}{m}\\sum_{i=1}^{m} \\log{(1+e^{x_{i,*}\\theta})}-(y_i)(x_{i,*}\\theta)$$\n",
    "\n",
    "$$J(\\theta)=-\\frac{1}{m}(\\tilde{X}\\theta)^tY+\\frac{1}{m}\\sum_{i=1}^{m}\\log(1+e^{x_{i,*}\\theta})$$\n",
    "\n",
    "\n",
    "We can now easily compute partial derivatives\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial\\theta_k} = \\frac{1}{m}\\sum_{i=1}^{m} \\frac{x_{ik}e^{x_{i,*}\\theta}}{1+e^{x_{i,*}\\theta}} - x_{ik}y_i$$\n",
    "\n",
    "$$ = \\frac{1}{m}\\sum_{i=1}^{m} x_{ik} \\biggl(\\frac{1}{1+e^{-x_{i,*}\\theta}} - y_i\\biggl)$$\n",
    "\n",
    "$$ = \\frac{1}{m}\\sum_{i=1}^{m} x_{ik} (g(x_{i,*}\\theta) - y_i)$$\n",
    "\n",
    "$$ = \\frac{1}{m}(x_{*,k})^t[g(\\tilde{X}\\theta)-Y]$$\n",
    "\n",
    "It follows that\n",
    "\n",
    "$$\\nabla J = \\frac{1}{m}(\\tilde{X})^t[g(\\tilde{X}\\theta)-Y]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1497f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateCost(X, Y, theta):\n",
    "    return 1/len(X)*(np.log(1+np.exp(X@theta)).sum()-X@theta@Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12fc12d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def getNewTheta(X,Y, theta, alpha = 1):\n",
    "    c = sigmoid(X@theta)-Y\n",
    "    return theta-alpha*X.T@c/len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "518ac036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runLogisticRegression(X,Y, theta, steps, alpha = 1, log = False):\n",
    "    \n",
    "    ans = theta        \n",
    "    stepCount = [0]\n",
    "    cost = [calculateCost(X, Y, ans)]\n",
    "\n",
    "    for i in range(steps):\n",
    "        ans = getNewTheta(X, Y, ans, alpha)\n",
    "        cost.append(calculateCost(X, Y, ans))\n",
    "        stepCount.append(i+1)\n",
    "        \n",
    "    plt.scatter(stepCount, cost)\n",
    "    plt.title('Cost vs Steps')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Cost')\n",
    "    \n",
    "    if log:\n",
    "        plt.xscale('log')\n",
    "        plt.yscale('log')\n",
    "    \n",
    "    plt.show()\n",
    "        \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27b21302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# have not yet tested if this code actually works since I have not found some sample data fit for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f014b14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c243c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the os module\n",
    "import os\n",
    "# Change the current working directory\n",
    "os.chdir('/Users/alexchandler/Documents/GitHub/knot_machine_learning/dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20acd510",
   "metadata": {},
   "outputs": [],
   "source": [
    "knot_info = pd.read_excel('knotinfo_data_complete.xls',\n",
    "skiprows = [1],\n",
    "header=0,\n",
    "index_col=False,\n",
    "keep_default_na=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0c4f954",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = knot_info[['determinant','signature','unknotting_number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "794df171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_list_to_int(unknotting):\n",
    "    try:\n",
    "        return int(unknotting)\n",
    "    except:\n",
    "        return -1\n",
    "    \n",
    "convert_list_to_int_vect = np.vectorize(convert_list_to_int)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f39c6205",
   "metadata": {},
   "outputs": [],
   "source": [
    "knot_info['unknotting_number'] = convert_list_to_int_vect(knot_info['unknotting_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1204e8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = knot_info['unknotting_number'] >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89e41942",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3cdb516",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = knot_info['alternating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00c17fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def YN_to_int(let):\n",
    "    if let == 'Y':\n",
    "        return 1\n",
    "    elif let == 'N':\n",
    "        return 0\n",
    "    else:\n",
    "        print(let)\n",
    "        \n",
    "YN_to_int_vect = np.vectorize(YN_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d529d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = YN_to_int_vect(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71059b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = yp[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70f971f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2316"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "445d8b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2316"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d901c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a1fd9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=3).fit(X, yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f08cc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8026770293609672"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X,yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05ce2bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6701208981001727"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(yp)/len(yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3329179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03063451, 0.02157264, 0.24040202]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3aacd1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57772021 0.8626943  0.78108808]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7405008635578584"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(clf, X, yp, cv=3))\n",
    "cross_val_score(clf, X, yp, cv=3).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a442c2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
